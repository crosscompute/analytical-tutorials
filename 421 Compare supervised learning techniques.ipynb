{
 "metadata": {
  "name": "421 Compare supervised learning techniques"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the complete list of supervised learning algorithms available in scikit-learn, please see the [documentation](http://scikit-learn.org/dev/supervised_learning.html).\n",
      "\n",
      "- Classification\n",
      "- Regression\n",
      "\n",
      "- Hyper parameters\n",
      "- Estimated parameters\n",
      "\n",
      "- Loss function\n",
      "- Gradient descent\n",
      "- Overfitting\n",
      "- Regularization\n",
      "\n",
      "- Feature selection\n",
      "- Feature extraction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pylab as pl\n",
      "from sklearn import datasets, linear_model\n",
      "\n",
      "vectors = [\n",
      "    [0, 0], \n",
      "    [1, 1],\n",
      "    [2, 2],\n",
      "]\n",
      "targets = [\n",
      "    0,\n",
      "    1,\n",
      "    2,\n",
      "]\n",
      "iris = datasets.load_iris()\n",
      "boston = datasets.load_boston()\n",
      "diabetes = datasets.load_diabetes()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# [Generalized linear models](http://scikit-learn.org/dev/modules/linear_model.html)\n",
      "\n",
      "Generalized linear models compute a linear combination of the features to estimate the target variable."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Ordinary least squares](http://scikit-learn.org/dev/modules/linear_model.html#ordinary-least-squares)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = linear_model.LinearRegression()\n",
      "model.fit(vectors, targets)\n",
      "print model.coef_\n",
      "print model.intercept_\n",
      "print model.predict([3, 3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Exercise:\n",
      "# Fit a linear regression on the Boston House Prices dataset.\n",
      "# Look at the coefficients."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Ridge regression](http://scikit-learn.org/dev/modules/linear_model.html#ridge-regression)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = linear_model.Ridge(alpha=0.5)\n",
      "model.fit(vectors, targets)\n",
      "print model.coef_\n",
      "print model.intercept_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])\n",
      "model.fit(vectors, targets)\n",
      "model.alpha_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Exercise:\n",
      "# Find an optimal value of alpha for\n",
      "# Ridge Regression on the Boston House Prices dataset."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Lasso](http://scikit-learn.org/dev/modules/linear_model.html#lasso)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = linear_model.Lasso(alpha=0.1)\n",
      "model.fit(vectors, targets)\n",
      "print model.coef_\n",
      "print model.intercept_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Adapted from\n",
      "# http://scikit-learn.org/dev/auto_examples/linear_model/plot_lasso_model_selection.html\n",
      "model = linear_model.LassoCV(cv=20)\n",
      "model.fit(diabetes.data, diabetes.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_model_selection(model):\n",
      "    logAlphas = -np.log10(model.alphas_)\n",
      "    pl.figure()\n",
      "    pl.plot(logAlphas, model.mse_path_, ':')\n",
      "    pl.plot(logAlphas, model.mse_path_.mean(axis=-1), 'k',\n",
      "        label='Average across folds', linewidth=2)\n",
      "    pl.axvline(-np.log10(model.alpha_), linestyle='--', color='k', \n",
      "        label='alpha: CV estimate')\n",
      "    pl.legend()\n",
      "    pl.title('Mean square error on each fold: Coordinate descent')\n",
      "    pl.xlabel('-log(alpha)')\n",
      "    pl.ylabel('Mean square error')\n",
      "    pl.axis('tight')\n",
      "    pl.ylim(2300, 3800)\n",
      "    \n",
      "plot_model_selection(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Lasso least angle regression](http://scikit-learn.org/dev/modules/linear_model.html#least-angle-regression)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = linear_model.LassoLars(alpha=0.1)\n",
      "model.fit(vectors, targets)\n",
      "print model.coef_\n",
      "print model.intercept_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Adapted from\n",
      "# http://scikit-learn.org/dev/auto_examples/linear_model/plot_lasso_model_selection.html\n",
      "model = linear_model.LassoLarsIC(criterion='bic')\n",
      "model.fit(diabetes.data, diabetes.target)\n",
      "\n",
      "pl.figure()\n",
      "pl.plot(-np.log10(model.alphas_), model.criterion_, '--', linewidth=3)\n",
      "pl.axvline(-np.log10(model.alpha_), linewidth=3)\n",
      "pl.xlabel('-log(alpha)')\n",
      "pl.ylabel('Information criterion')\n",
      "pl.title('Model selection by information criterion');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Exercise:\n",
      "# Modify the above example to use the Akaike information criterion\n",
      "# instead of the Bayes Information criterion."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Exercise:\n",
      "# Use cross validation instead of information criterion\n",
      "# to select alpha."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Bayesian regression](http://scikit-learn.org/dev/modules/linear_model.html#bayesian-ridge-regression)\n",
      "\n",
      "Bayesian regression optimizes model parameters and regularization parameters at the same time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = linear_model.BayesianRidge()\n",
      "model.fit(vectors, targets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Logistic regression (classification)](http://scikit-learn.org/dev/modules/linear_model.html#logisitic-regression)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = linear_model.LogisticRegression()\n",
      "model.fit(iris.data[:-1], iris.target[:-1])\n",
      "print model.predict(iris.data[-1])\n",
      "print iris.target[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# [Support vector machines](http://scikit-learn.org/dev/modules/svm.html)\n",
      "\n",
      "Support vector machines draw a boundary to estimate the target variable."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# [Nearest neighbors](http://scikit-learn.org/dev/modules/neighbors.html)\n",
      "# [Gaussian processes](http://scikit-learn.org/dev/modules/gaussian_process.html)\n",
      "# [Decision trees](http://scikit-learn.org/dev/modules/tree.html)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}